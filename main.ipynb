{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ysg9IUvkScqr"
      },
      "outputs": [],
      "source": [
        "#pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erQw0mEzS1om",
        "outputId": "3ad06414-5865-4d05-9588-3056704f1ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.3.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.41.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.4)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.32.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.23.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.5.82)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install peft\n",
        "%pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "GOqgflF0vf8p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WVmDRGVTGSK"
      },
      "source": [
        "Importing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "4xPWBDDVS_gL"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model_name = \"google/flan-t5-small\"\n",
        "# Check if CUDA is available and set device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
        "foundation_model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device) # Move the model to the device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkaJM7UvTcA9"
      },
      "source": [
        "Checking my model how it performs in zero shot for summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-p5egcKTID0",
        "outputId": "bf0de919-0075-4097-9d1a-870b251fe306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs: tensor([[ 9410,    10,  1079,   531,    15,  1820,  4300, 17179,  7187,    10,\n",
            "         10318,     6, 20737,     6,    11,   205, 16702,  8457,   203,    61,\n",
            "         26633, 25984,     6,   391,  6038,  1329,  6429,     7,     6,    11,\n",
            "          3501,   758,  2855,    10, 10199,    31,     7,  1952,    16,  5491,\n",
            "          2854,     6,     3,     4,   476,   956,   636, 12198,  1635,  1737,\n",
            "            48,  9410,    10,     1]])\n",
            "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1]])\n",
            "['John Doe is a software developer. He is a software engineer.']\n"
          ]
        }
      ],
      "source": [
        "# This is just to check the model with no fine tuning\n",
        "\n",
        "\n",
        "\n",
        "resume_text = \"John Doe | Software Developer Experience: Java, Python, and C++ (4 years) Agile methodologies, RESTful APIs, and database management Education: Bachelor's degree in Computer Science, XYZ University\"\n",
        "\n",
        "input1 = tokenizer(f\"Resume: {resume_text}\\nSummarize this Resume:\", return_tensors=\"pt\").to(device)\n",
        "print(\"Input IDs:\", input1[\"input_ids\"])\n",
        "print(\"Attention Mask:\", input1[\"attention_mask\"])\n",
        "foundation_outputs = foundation_model.generate(\n",
        "    input_ids=input1[\"input_ids\"],\n",
        "    attention_mask=input1[\"attention_mask\"],\n",
        "    max_new_tokens=150,\n",
        "    do_sample=True,\n",
        "    temperature=0.3,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    top_k=50,  # Use top-k sampling\n",
        "    top_p=0.9  # Use top-p (nucleus) sampling\n",
        "    )\n",
        "print(tokenizer.batch_decode(foundation_outputs, skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WD-9UKwnUVmL",
        "outputId": "1ada539b-5696-47f6-a188-231552deb824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "['Datasets', 'working_dir', 'runs', 'peft_model_1720299458.6191595']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "output_directory = \"/content/drive/MyDrive/Colab Notebooks/Text Summarization/\"\n",
        "\n",
        "if not os.path.exists(output_directory):\n",
        "    os.mkdir(output_directory)\n",
        "\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/Text Summarization'\n",
        "files = os.listdir(path)\n",
        "print(files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hwMWQOkUt9A"
      },
      "source": [
        "# **Load The Resume dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbMmwc6GT4rJ",
        "outputId": "979462e4-80d2-485b-fb3f-8a42e32e9564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['resume', 'ex_summary'],\n",
            "        num_rows: 100\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset, DatasetDict,Dataset\n",
        "\n",
        "ds = load_dataset(\"burberg92/resume_summary\",cache_dir=\"/content/drive/MyDrive/Colab Notebooks/Text Summarization/Datasets\")\n",
        "print(ds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL_QxBxd4pRP"
      },
      "source": [
        "# **Creating custom prompt template**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "pbQPO5C-swrV"
      },
      "outputs": [],
      "source": [
        "def create_prompt(example):\n",
        "    return {'prompt':  example['resume'], 'summary': example['ex_summary']}\n",
        "\n",
        "# prompt_dataset = ds.map(create_prompt)\n",
        "# prompt_dataset = prompt_dataset.remove_columns(['resume', 'ex_summary'])\n",
        "# print(prompt_dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-jwTuFpwnOR",
        "outputId": "f43863c1-63d9-4f56-a660-cad9c20420a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['prompt', 'summary'],\n",
            "        num_rows: 100\n",
            "    })\n",
            "})\n",
            "--------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'summary', 'text'],\n",
              "    num_rows: 100\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "# Define the function to create prompt formats\n",
        "def create_prompt_formats(sample):\n",
        "    \"\"\"\n",
        "    Format various fields of the sample ('instruction','output')\n",
        "    Then concatenate them using two newline characters\n",
        "    :param sample: Sample dictionary\n",
        "    \"\"\"\n",
        "    INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
        "    INSTRUCTION_KEY = \"### Instruct: Summarize the below conversation.\"\n",
        "    RESPONSE_KEY = \"### Summary:\"\n",
        "    END_KEY = \"### End\"\n",
        "\n",
        "    blurb = f\"\\n{INTRO_BLURB}\"\n",
        "    instruction = f\"{INSTRUCTION_KEY}\"\n",
        "    input_context = f\"{sample['prompt']}\" if sample[\"prompt\"] else None\n",
        "    response = f\"{RESPONSE_KEY}\\n{sample['summary']}\"\n",
        "    end = f\"{END_KEY}\"\n",
        "\n",
        "    parts = [part for part in [blurb, instruction, input_context, response, end] if part]\n",
        "\n",
        "    formatted_prompt = \"\\n\\n\".join(parts)\n",
        "    sample[\"text\"] = formatted_prompt\n",
        "\n",
        "    return sample\n",
        "\n",
        "# Apply the function to create the prompt dataset\n",
        "prompt_dataset = ds.map(create_prompt)\n",
        "prompt_dataset = prompt_dataset.remove_columns(['resume', 'ex_summary'])\n",
        "print(prompt_dataset)\n",
        "print('--------')\n",
        "# Apply the function to create the prompt formats\n",
        "formatted_prompt_dataset = prompt_dataset.map(create_prompt_formats)\n",
        "\n",
        "# Check the first few examples to ensure the prompts are formatted correctly\n",
        "formatted_prompt_dataset['train']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7Frhw126dSs"
      },
      "source": [
        "Splitting the data into training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuiObdHG4oTS",
        "outputId": "d7e56d46-5484-43d4-bb1e-9bc6057fa08c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['prompt', 'summary', 'text'],\n",
            "        num_rows: 80\n",
            "    })\n",
            "    val: Dataset({\n",
            "        features: ['prompt', 'summary', 'text'],\n",
            "        num_rows: 20\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "k = formatted_prompt_dataset['train'].train_test_split(test_size=0.2)\n",
        "\n",
        "data_slpit=DatasetDict({\n",
        "    'train':k['train'],\n",
        "    'val':k['test']\n",
        "})\n",
        "print(data_slpit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "zkO9ghnB_h1T",
        "outputId": "7d50a9f8-f6e0-48de-b543-8fe741c64898"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Results-driven Product Manager with 5 years of experience in product lifecycle management, market research, and roadmap development. Skilled in Agile methodologies and collaboration with cross-functional teams. Holds a Bachelor's degree in Business Administration from NOP University.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "formatted_prompt_dataset['train']['summary'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1Zt6FeEzjRZ"
      },
      "source": [
        "Max lenght of tokens that the model can hold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "981qpfJ2y5qx",
        "outputId": "5fac8fcc-c923-42b5-f493-15ff8cb5baff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found max lenth: 512\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "def get_max_length(model):\n",
        "    conf = model.config\n",
        "    max_length = None\n",
        "    for length_setting in [\"n_positions\", \"max_position_embeddings\", \"seq_length\"]:\n",
        "        max_length = getattr(model.config, length_setting, None)\n",
        "        if max_length:\n",
        "            print(f\"Found max lenth: {max_length}\")\n",
        "            break\n",
        "    if not max_length:\n",
        "        max_length = 1024\n",
        "        print(f\"Using default max length: {max_length}\")\n",
        "    return max_length\n",
        "\n",
        "\n",
        "get_max_length(foundation_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1bExowk6l7C"
      },
      "source": [
        "Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKQIu3sk7MeU"
      },
      "source": [
        "Finding maximum token size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "a9a293eecc2845f782b19d3538502565",
            "b0e5f09b779c409eb20074aded83884d",
            "2717d6293d884469964560df007fdc81",
            "2795a32ef8bd49c6876c0a4c06dd754e",
            "b65c8ebc05084eb4b9fe85ffb782fba4",
            "d1ad1506220d4207a82bf609e09bd266",
            "fd509685d2294e26af4fac7f50111674",
            "b57d6c38e7c742f8a2b6d5bce6e83d7c",
            "52fcd9bf3e6b48d58581f39d2d193038",
            "77e749d36771437fa6489e95e101b745",
            "b9622e4d9370480d8de53a91467553bd",
            "b64414a657f34a4ba693e7e32b4bc931",
            "0b7597bd8c1f44dc871ee670ad3b8e7b",
            "c9c7eb338e494a50bd30680ff17e148e",
            "07a1c3e858f14cb5baf9dabf0c36d852",
            "52bb2f8df57941c68595b5b957160c83",
            "5cc39e168071459d9e9cfca150c859e7",
            "02418721a61940dc9ee8c4bbbfe0fb52",
            "a0091994f8624c3f85e61d028c5ae317",
            "b69750180ee6460e88db70931fa450b4",
            "e9fc614f8c024bc1aeb2593b5563a519",
            "a8403fde68184f72aa8650d1e3e96a8d"
          ]
        },
        "id": "07yRth3x2kH9",
        "outputId": "10f14999-71ac-4b52-a17d-fa26b4c3f61b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9a293eecc2845f782b19d3538502565"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b64414a657f34a4ba693e7e32b4bc931"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum token length in the dataset: 167\n"
          ]
        }
      ],
      "source": [
        "# Function to tokenize the prompts\n",
        "def tokenize_and_find_length(example):\n",
        "    tokens = tokenizer(example['prompt'], truncation=False)\n",
        "    example['input_length'] = len(tokens['input_ids'])\n",
        "    return example\n",
        "\n",
        "# Apply the function to the dataset to find the length of each tokenized sequence\n",
        "tokenized_lengths_dataset = data_slpit.map(tokenize_and_find_length, batched=False)\n",
        "\n",
        "# Find the maximum token length in the dataset\n",
        "max_token_length = max(tokenized_lengths_dataset['train']['input_length'])\n",
        "print(f\"Maximum token length in the dataset: {max_token_length}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172,
          "referenced_widgets": [
            "6cd9043b0e7a441dbc6315e0ba279dd3",
            "0f4ae6e80a6846b88e8a325c2b86a767",
            "2522929143ea453182c1a1b6e255d28d",
            "63a13b044370423aa5400bc66ce2f83f",
            "9791d0d4fde84483b244f5f9b12125f3",
            "ded80243d9f64e659a65bfe7505c6506",
            "030128bd0e144e73b9cd721d636a5544",
            "8f1d5008ee124d66b2e8a22b3e160d16",
            "b9f8b0728821484180d98f8d5ea7f3df",
            "d0e81846a1074dd088c7af5722a788b7",
            "f46d870e3ba6476183d7a66a569fa93c",
            "cfad7e7afa9d4a7893f55bbdf7886ba0",
            "98da5a0cca1b496095bf164dcb157bc6",
            "9d9245e0f13848049fdfac94f35167d9",
            "794b35debcb34fdfbb99263241b2b444",
            "060b8683a53e409a9782bb9db9876ed4",
            "7aa27e15c83145358d08e579099b1f3c",
            "c4298f931e354e98820bfa1b24552bff",
            "f3012d22ff8142d4aa3d2f886a5074a9",
            "375a39e3824b4a6880ed8afcba7ab85d",
            "dc6e3dbdd0184512a5efded3146f8f1c",
            "eacd4084c6284a2998ee61dbcdb97377"
          ]
        },
        "id": "Q-VBJZJi0FFN",
        "outputId": "bffe1dec-a76d-4e50-d527-428dfb47398e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cd9043b0e7a441dbc6315e0ba279dd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfad7e7afa9d4a7893f55bbdf7886ba0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12254, 13521, 1820, 24483, 11597, 9020, 19559, 10, 24483, 408, 6, 556, 606, 6, 11, 3, 12926, 889, 749, 17397, 16, 12974, 12492, 7, 6, 2040, 12926, 6, 11, 3188, 7980, 262, 3335, 10582, 41, 6392, 188, 61, 3118, 5528, 10, 24483, 5623, 3037, 29, 6, 480, 11160, 19193, 25195, 4224, 15, 26, 408, 11, 556, 606, 1195, 4001, 15, 26, 81, 3, 12926, 889, 11, 3, 6392, 188, 24483, 11597, 6, 283, 7400, 18080, 41, 10218, 7988, 2773, 61, 3, 14454, 11, 1597, 8168, 1002, 11, 494, 20156, 15, 26, 3, 12926, 889, 11, 3, 6392, 188, 21, 408, 11295, 2855, 10, 10199, 31, 7, 1952, 16, 24483, 5623, 6, 276, 2247, 448, 636, 41, 16660, 18, 11138, 61, 1], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 27917, 24483, 11597, 28, 2980, 16, 8168, 408, 6, 556, 606, 6, 11, 3, 12926, 889, 5, 749, 17397, 16, 12974, 12492, 7, 6, 2040, 12926, 6, 11, 3188, 7980, 262, 3335, 10582, 41, 6392, 188, 201, 28, 351, 16, 8296, 11, 19769, 53, 8168, 1002, 11, 494, 5, 8470, 7, 3, 9, 10199, 31, 7, 1952, 16, 24483, 5623, 45, 276, 2247, 448, 636, 5, 1]}\n",
            "{'input_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4599, 5531, 1820, 16297, 11296, 4420, 24797, 11573, 10, 16297, 408, 6, 14282, 6, 11, 3176, 1901, 749, 17397, 16, 11551, 9470, 9254, 11, 28396, 1642, 19559, 10, 15327, 408, 6, 23042, 16369, 6, 11, 5315, 3118, 7187, 10, 16297, 1642, 3037, 29, 6, 262, 22807, 1642, 5929, 25195, 3, 31606, 28, 408, 1195, 11, 1597, 1098, 16, 11551, 9470, 9254, 15077, 920, 16, 1188, 4677, 11, 408, 9972, 16297, 11296, 6, 350, 7094, 9470, 7038, 41, 10218, 7988, 2773, 61, 6357, 26, 14282, 1397, 6, 379, 3554, 7, 6, 2281, 25028, 6, 11, 1125, 4089, 3043, 9456, 920, 28, 820, 12, 1344, 775, 11, 1231, 3176, 1901, 1275, 2855, 10, 10199, 31, 7, 1952, 16, 16297, 1642, 6, 27, 683, 439, 636, 41, 16660, 18, 11138, 61, 1], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 27917, 16297, 11296, 28, 2980, 16, 7693, 408, 6, 14282, 6, 11, 3176, 1901, 5, 749, 17397, 16, 11551, 9470, 9254, 11, 28396, 6, 28, 1101, 1098, 16, 3554, 408, 6, 23042, 16369, 6, 11, 5315, 5, 8470, 7, 3, 9, 10199, 31, 7, 1952, 16, 16297, 1642, 45, 27, 683, 439, 636, 5, 1]}\n"
          ]
        }
      ],
      "source": [
        "def tokenize_function(example):\n",
        "    model_inputs = tokenizer(example['prompt'], truncation=True, padding='max_length', max_length=max_token_length)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(example['summary'], truncation=True, padding='max_length', max_length=78)\n",
        "    model_inputs['labels'] = labels['input_ids']\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_dataset = data_slpit.map(tokenize_function, batched=True, remove_columns=['prompt', 'summary', 'text'])\n",
        "print(tokenized_dataset['train'][0])\n",
        "print(tokenized_dataset['val'][0])\n",
        "\n",
        "train_sample=tokenized_dataset['train']\n",
        "val_sample=tokenized_dataset['val']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PUqJ-jtg8q41"
      },
      "outputs": [],
      "source": [
        "# # Function to detokenize the token IDs\n",
        "# def detokenize_function(example):\n",
        "#     example['decoded_text'] = tokenizer.decode(example['input_ids'], skip_special_tokens=True)\n",
        "#     #example['decoded_summary'] = tokenizer.decode(example['labels'], skip_special_tokens=True)\n",
        "#     return example\n",
        "\n",
        "# # Apply the detokenization function to the validation sample\n",
        "# detokenized_val_sample = val_sample.map(detokenize_function, batched=False)\n",
        "\n",
        "# # Print the first few examples to see the results\n",
        "# for i in range(1):\n",
        "#     print(f\"Decoded Text {i+1}: {detokenized_val_sample[i]['decoded_text']}\")\n",
        "#     #print(f\"Decoded Summary {i+1}: {detokenized_val_sample[i]['decoded_summary']}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ipMaLjRuoba"
      },
      "source": [
        "# **Random Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "nU19_zEfABlj"
      },
      "outputs": [],
      "source": [
        "from peft import  get_peft_model, PromptTuningConfig, TaskType, PromptTuningInit\n",
        "from transformers import Seq2SeqTrainingArguments,DataCollatorForSeq2Seq,Seq2SeqTrainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "gaWZwF0wdjOG"
      },
      "outputs": [],
      "source": [
        "from peft import  get_peft_model, PromptTuningConfig, TaskType, PromptTuningInit\n",
        "\n",
        "peft_config = PromptTuningConfig(\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "    prompt_tuning_init=PromptTuningInit.RANDOM,\n",
        "    num_virtual_tokens=4,\n",
        "    tokenizer_name_or_path=model_name\n",
        ")\n",
        "peft_model = get_peft_model(foundation_model, peft_config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4dNwZhTd901",
        "outputId": "21f2374c-7eb4-4c8b-a79c-a6613e64a54b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 6,144 || all params: 76,967,296 || trainable%: 0.0080\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(peft_model.print_trainable_parameters())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9fwCtb9fODQ"
      },
      "source": [
        "Creating a directory for training parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "ssL8rHA0fDgI"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "\n",
        "output_directory = \"/content/drive/MyDrive/Colab Notebooks/Text Summarization/working_dir\"\n",
        "\n",
        "if not os.path.exists(output_directory):\n",
        "    os.mkdir(output_directory)\n",
        "if not os.path.exists(output_directory):\n",
        "    os.mkdir(output_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0iW_2Q5uPqF",
        "outputId": "5c6388fd-7436-4190-b276-8c22faf392de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.41.2\n",
            "0.32.1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#pip install accelerate -U\n",
        "import transformers\n",
        "import accelerate\n",
        "\n",
        "print(transformers.__version__)\n",
        "print(accelerate.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FWhfj-_0X1wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "ZKXWsyIrfNdK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7307865c-3941-451a-f067-f8c6e9e2d171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#%%\n",
        "from transformers import Seq2SeqTrainingArguments\n",
        "# training_args = Seq2SeqTrainingArguments(\n",
        "#     output_dir=output_directory,          # output directory\n",
        "#     evaluation_strategy=\"epoch\",     # evaluation strategy to use\n",
        "#     per_device_train_batch_size=2,   # batch size for training\n",
        "#     per_device_eval_batch_size=2,    # batch size for evaluation\n",
        "#     weight_decay=0.01,               # strength of weight decay\n",
        "#     save_total_limit=1,              # limit the total amount of checkpoints\n",
        "#     num_train_epochs=5,              # total number of training epochs\n",
        "#     learning_rate=5e-3,              # learning rate\n",
        "#     predict_with_generate=True       # Whether to use generate to calculate generative metrics (ROUGE, BLEU)\n",
        "\n",
        "# )\n",
        "\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=output_directory,          # output directory\n",
        "    evaluation_strategy=\"epoch\",     # evaluation strategy to use\n",
        "    per_device_train_batch_size=2,   # batch size for training\n",
        "    per_device_eval_batch_size=2,    # batch size for evaluation\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    save_total_limit=1,              # limit the total amount of checkpoints\n",
        "    num_train_epochs=7,              # total number of training epochs\n",
        "    learning_rate=5e-3,              # learning rate\n",
        "    predict_with_generate=True,      # Whether to use generate to calculate generative metrics (ROUGE, BLEU)\n",
        "    logging_strategy=\"steps\",        # Log at each logging step\n",
        "    logging_steps=10,                # Log every 10 steps\n",
        "    report_to=\"none\"                 # Avoid logging to external services\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "s4fPT31oFR-U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6da937a9-51d0-4ccf-83e6-df961eabd8f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "%pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "bqBHL0yBhJQk",
        "outputId": "a50e5280-706b-43da-99ea-8794e288f298"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='280' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [280/280 09:25, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>14.715300</td>\n",
              "      <td>12.762418</td>\n",
              "      <td>38.490983</td>\n",
              "      <td>32.251691</td>\n",
              "      <td>33.251202</td>\n",
              "      <td>33.316595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>13.362200</td>\n",
              "      <td>12.610611</td>\n",
              "      <td>37.783799</td>\n",
              "      <td>32.131250</td>\n",
              "      <td>33.060663</td>\n",
              "      <td>33.136308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>12.791800</td>\n",
              "      <td>12.525662</td>\n",
              "      <td>39.014161</td>\n",
              "      <td>33.030236</td>\n",
              "      <td>34.360410</td>\n",
              "      <td>34.118034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>12.997300</td>\n",
              "      <td>12.345935</td>\n",
              "      <td>40.286581</td>\n",
              "      <td>35.217883</td>\n",
              "      <td>35.471301</td>\n",
              "      <td>35.125848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>13.691900</td>\n",
              "      <td>12.239588</td>\n",
              "      <td>42.363016</td>\n",
              "      <td>37.088750</td>\n",
              "      <td>37.335174</td>\n",
              "      <td>37.058821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>11.379400</td>\n",
              "      <td>12.203250</td>\n",
              "      <td>41.410499</td>\n",
              "      <td>36.233558</td>\n",
              "      <td>36.238735</td>\n",
              "      <td>36.109370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>11.566000</td>\n",
              "      <td>12.184464</td>\n",
              "      <td>42.385833</td>\n",
              "      <td>36.371148</td>\n",
              "      <td>36.161039</td>\n",
              "      <td>35.998415</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=280, training_loss=13.326544543675015, metrics={'train_runtime': 570.2648, 'train_samples_per_second': 0.982, 'train_steps_per_second': 0.491, 'total_flos': 33954062499840.0, 'train_loss': 13.326544543675015, 'epoch': 7.0})"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "\n",
        "# for text generation DataCollatorForLanguageModeling is used\n",
        "# for text summarization as it is a sequence to sequence task\n",
        "\n",
        "from transformers import Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
        "\n",
        "from datasets import load_metric\n",
        "# Define the ROUGE metric function\n",
        "rouge = load_metric(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 in the labels as we can't decode them\n",
        "    decoded_labels = [\n",
        "        [label if label != -100 else tokenizer.pad_token_id for label in labels]\n",
        "        for labels in decoded_labels\n",
        "    ]\n",
        "\n",
        "    # Join tokens to form strings\n",
        "    decoded_preds = [\" \".join(pred) for pred in decoded_preds]\n",
        "    decoded_labels = [\" \".join(label) for label in decoded_labels]\n",
        "\n",
        "    # Compute ROUGE scores\n",
        "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "\n",
        "    # Extract the individual scores\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "\n",
        "    return result\n",
        "\n",
        "# Prepare data collator\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=foundation_model,padding=True)\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=peft_model,                      # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                    # training arguments\n",
        "    train_dataset=train_sample,            # training dataset\n",
        "    eval_dataset=val_sample,               # evaluation dataset\n",
        "    tokenizer=tokenizer,                   # tokenizer\n",
        "    data_collator=data_collator,           # data collator\n",
        "    compute_metrics=compute_metrics        # custom metrics\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILC2DuL8jtkP",
        "outputId": "a8da2b86-69e6-42e2-eef9-c93c499dfe75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "time_now = time.time()\n",
        "peft_model_path = os.path.join(output_directory, f\"peft_model_{time_now}\")\n",
        "trainer.model.save_pretrained(peft_model_path,force_download=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3O4FgKzj5y0",
        "outputId": "f04700b0-2820-46f1-9e69-8e6ffdabc886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: \n",
            "Resume:\n",
            "Richik Ghosh | Project Manager Experience: Managing cross-functional teams, risk mitigation, and resource allocation (6 years) Certified PMP and Scrum Master Strong background in IT and software development projects Education: Master's degree in Business Administration, MNO University\n",
            "genrate a summary of the above resume\n",
            "\n",
            "Summary: Richik Ghosh | Project Manager Experience: Managing cross-functional teams, risk mitigation, and resource allocation (6 years) Certified PMP and Scrum Master Strong background in IT and software development projects\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "#load the trained model\n",
        "loaded_model = PeftModel.from_pretrained(foundation_model,\n",
        "                                         peft_model_path,\n",
        "                                         is_trainable=False,\n",
        "                                         torch_dtype=torch.float16 # Ensure model weights are in float16\n",
        "                                         #device_map={\"\":0}\n",
        "                                         ) # Load the model on the first available GPU (index 0)\n",
        "\n",
        "\n",
        "# Function to generate summary from a prompt\n",
        "def summarize(prompt, max_length=300, num_beams=2,length_penalty=2.0):\n",
        "    # Tokenize the input prompt\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=max_token_length, truncation=True)\n",
        "\n",
        "    # Generate summary\n",
        "    loaded_model_outputs = loaded_model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],#.to('cuda'),  # Move input tensors to GPU\n",
        "        attention_mask=inputs[\"attention_mask\"],#.to('cuda'),  # Move attention mask tensors to GPU\n",
        "        max_length=max_length,\n",
        "        num_beams=num_beams,\n",
        "        do_sample=True,\n",
        "        #early_stopping=True,\n",
        "        length_penalty=length_penalty,\n",
        "        temperature=0.9,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        #max_new_tokens=100,\n",
        "        top_k=50,  # Use top-k sampling\n",
        "        top_p=0.95\n",
        "\n",
        "    )\n",
        "\n",
        "    # Decode the output\n",
        "    summary = tokenizer.batch_decode(loaded_model_outputs, skip_special_tokens=True)\n",
        "    return summary[0]\n",
        "\n",
        "# Example prompt\n",
        "prompt = \"\"\"\n",
        "Resume:\n",
        "Richik Ghosh | Project Manager Experience: Managing cross-functional teams, risk mitigation, and resource allocation (6 years) Certified PMP and Scrum Master Strong background in IT and software development projects Education: Master's degree in Business Administration, MNO University\n",
        "genrate a summary of the above resume\n",
        "\"\"\"\n",
        "\n",
        "# Generate and print the summary\n",
        "summary = summarize(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Summary:\", summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtWldwtZt3SI"
      },
      "source": [
        "# **Text Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsVOwPM50EFR",
        "outputId": "3d2142cb-08b3-45f0-a7ad-19a0e22f34db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 7,168 || all params: 76,968,320 || trainable%: 0.0093\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "\n",
        "text_peft_config = PromptTuningConfig(\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "    prompt_tuning_init=PromptTuningInit.TEXT,\n",
        "    prompt_tuning_init_text=\"Generate Resume Summary\", # this provides a starter for the model to start searching for the best embeddings\n",
        "    num_virtual_tokens=7, # this doesn't have to match the length of the text above\n",
        "    tokenizer_name_or_path=model_name\n",
        ")\n",
        "\n",
        "\n",
        "text_peft_model = get_peft_model(foundation_model, text_peft_config)\n",
        "print(text_peft_model.print_trainable_parameters())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "J6wl4pzB0DxW",
        "outputId": "f7ef82f1-6fbe-44f7-94e0-906d70ebb0f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/200 14:55, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>35.386800</td>\n",
              "      <td>38.590141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>35.882100</td>\n",
              "      <td>38.588055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>34.385300</td>\n",
              "      <td>38.586544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>35.044000</td>\n",
              "      <td>38.585575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>35.824500</td>\n",
              "      <td>38.585274</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=200, training_loss=35.41623489379883, metrics={'train_runtime': 900.7288, 'train_samples_per_second': 0.444, 'train_steps_per_second': 0.222, 'total_flos': 41534909644800.0, 'train_loss': 35.41623489379883, 'epoch': 5.0})"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=output_directory,          # output directory\n",
        "    evaluation_strategy=\"epoch\",     # evaluation strategy to use\n",
        "    per_device_train_batch_size=2,   # batch size for training\n",
        "    per_device_eval_batch_size=2,    # batch size for evaluation\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    save_total_limit=1,              # limit the total amount of checkpoints\n",
        "    num_train_epochs=5,              # total number of training epochs\n",
        "    learning_rate=5e-5,              # learning rate\n",
        "    predict_with_generate=True,      # Whether to use generate to calculate generative metrics (ROUGE, BLEU)\n",
        "    logging_strategy=\"steps\",        # Log at each logging step\n",
        "    logging_steps=10,                # Log every 10 steps\n",
        "    report_to=\"none\"                 # Avoid logging to external services\n",
        ")\n",
        "text_trainer = Trainer(\n",
        "    model=text_peft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_sample,\n",
        "    eval_dataset=val_sample,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "text_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMnRqf2M1a10",
        "outputId": "de94176d-79b9-4d46-885d-8eaa92939166"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Save the model\n",
        "time_now = time.time()\n",
        "text_peft_model_path = os.path.join(output_directory, f\"text_peft_model_{time_now}\")\n",
        "text_trainer.model.save_pretrained(text_peft_model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHbBv09A1b2K"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "loaded_text_model = PeftModel.from_pretrained(foundation_model,\n",
        "    text_peft_model_path,\n",
        "    is_trainable=False)   #device_map={\"\":0})\n",
        "\n",
        "#loaded_text_model.to('cuda') # Move the entire model to the GPU\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx9H6XbP1eZ0"
      },
      "outputs": [],
      "source": [
        "# Generate output\n",
        "text_outputs = loaded_text_model.generate(\n",
        "    input_ids=input1[\"input_ids\"],#.to('cuda'), # Move input tensors to GPU\n",
        "    attention_mask=input1[\"attention_mask\"],#.to('cuda'), # Move attention mask tensors to GPU\n",
        "    max_new_tokens=40,\n",
        "    eos_token_id=tokenizer.eos_token_id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QutiuSP22fqa",
        "outputId": "05b6d141-e2f6-43ca-ab69-4af0b98ee3fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['John Doe is a software developer. He is a software engineer.']\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.batch_decode(text_outputs, skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6vd4uFsYoQs"
      },
      "source": [
        "# Using QLORA for the quantization technique.\n",
        "The quantization techniques helps mostly for decreasing the bit size.\n",
        "This helps running the model with lower computaion power."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7MiUMiS3Yn5q"
      },
      "outputs": [],
      "source": [
        "from peft import prepare_model_for_kbit_training,PeftModel\n",
        "import transformers\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "\n",
        "from peft import LoraConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voyOIpHQWdhJ",
        "outputId": "7e82a4b3-115e-4933-e44a-9dfbe89c8d8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Installing collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.1\n"
          ]
        }
      ],
      "source": [
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2jLiYlYQLry"
      },
      "source": [
        "Load quantized model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7RppPbpwPfDW"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_name,\n",
        "    #device_map=\"auto\",  # the model finds the optized way to distribute the load equally betwn GPU and CPU\n",
        "    trust_remote_code=False,  # not allow custom model files\n",
        "    revision=\"main\",  # main version to be retrived\n",
        "    # Removed the redundant load_in_4bit argument here\n",
        "    # quantization_config=BitsAndBytesConfig(\n",
        "    #     load_in_4bit=True,\n",
        "    #     bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    #     bnb_4bit_use_double_quant=True,\n",
        "    #     bnb_4bit_quant_type='nf4'\n",
        "    # )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "JqhljEbXU7ht"
      },
      "outputs": [],
      "source": [
        "model.train()\n",
        "model.gradient_checkpointing_enable()\n",
        "model= prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vadI-uF9XlHF",
        "outputId": "a6c04110-2dcf-42cb-8366-b0ae07d9a349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 344064\n",
            "Total parameters: 77305216\n",
            "Percentage of trainable parameters: 0.45%\n"
          ]
        }
      ],
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_2_SEQ_LM\"\n",
        ")\n",
        "def print_trainable_parameters(model):\n",
        "    trainable_params = 0\n",
        "    total_params = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        total_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "            #print(f\"Trainable parameter: {name}, shape: {param.shape}\")\n",
        "    print(f\"Trainable parameters: {trainable_params}\")\n",
        "    print(f\"Total parameters: {total_params}\")\n",
        "    print(f\"Percentage of trainable parameters: {100 * trainable_params / total_params:.2f}%\")\n",
        "\n",
        "peft_model=get_peft_model(model,lora_config)\n",
        "print_trainable_parameters(peft_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19NAUuNnY5pR",
        "outputId": "22556fd9-19e4-4fde-f357-cc486833793f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_args=transformers.TrainingArguments(\n",
        "    output_dir=output_directory,\n",
        "    learning_rate=2e-4,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        "    logging_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    gradient_accumulation_steps=4,\n",
        "    warmup_steps=2,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True, # 16bit value for training\n",
        "    optim=\"paged_adamw_8bit\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "vHk-F0gvdEfL",
        "outputId": "391d7b37-2de0-4453-ee5f-a56f6503011a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [400/400 23:06, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.119600</td>\n",
              "      <td>2.681428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.367800</td>\n",
              "      <td>2.060570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.137700</td>\n",
              "      <td>1.807211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.897000</td>\n",
              "      <td>1.719469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.768300</td>\n",
              "      <td>1.650465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.787800</td>\n",
              "      <td>1.666389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.675600</td>\n",
              "      <td>1.605616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.687600</td>\n",
              "      <td>1.586604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.645200</td>\n",
              "      <td>1.605831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.634400</td>\n",
              "      <td>1.579153</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=400, training_loss=2.1662225103378296, metrics={'train_runtime': 1392.7662, 'train_samples_per_second': 0.574, 'train_steps_per_second': 0.287, 'total_flos': 48781605273600.0, 'train_loss': 2.1662225103378296, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=output_directory,          # output directory\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=10,\n",
        "    eval_steps=50,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=1,\n",
        "    num_train_epochs=10,\n",
        "    learning_rate=5e-3,\n",
        "    predict_with_generate=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=foundation_model)\n",
        "\n",
        "text_trainer = transformers.Trainer(\n",
        "    model=peft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_sample,\n",
        "    eval_dataset=val_sample,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "\n",
        "#model.config.use_cache = False\n",
        "text_trainer.train()\n",
        "#model.config.use_cache =True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "oBJjPCYZeaWy"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "import time\n",
        "time_now = time.time()\n",
        "loRA_peft_model_path = os.path.join(output_directory, f\"loRA_peft_model_{time_now}\")\n",
        "text_trainer.model.save_pretrained(loRA_peft_model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_i0tSlcid7n",
        "outputId": "0044d289-11c2-4ab2-845b-de1b93b7204d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: \n",
            "Resume:\n",
            "Olivia Wilson | Human Resources Coordinator Experience: Employee relations, benefits administration, and talent acquisition (4 years)Skilled in HRIS, conflict resolution, and legal compliance Education: Bachelor's degree in Human Resources Management, JKL University\n",
            "Summary:\n",
            "\n",
            "Summary: -efficient Human Resources Coordinator with experience in employee relations, benefits administration, and talent acquisition. Talent in HRIS, conflict resolution, and legal compliance, with a bachelor's degree in Human Resources Management from JKL University.\n"
          ]
        }
      ],
      "source": [
        "loaded_model = PeftModel.from_pretrained(foundation_model,\n",
        "                                         loRA_peft_model_path,\n",
        "                                         is_trainable=False,\n",
        "                                         torch_dtype=torch.float16 # Ensure model weights are in float16\n",
        "                                         #device_map={\"\":0}\n",
        "                                         ) # Load the model on the first available GPU (index 0)\n",
        "\n",
        "\n",
        "# Function to generate summary from a prompt\n",
        "def summarize(prompt, max_length=300, num_beams=4,length_penalty=2.0):\n",
        "    # Tokenize the input prompt\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=200, truncation=True)\n",
        "\n",
        "    # Generate summary\n",
        "    loaded_model_outputs = loaded_model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],#.to('cuda'),  # Move input tensors to GPU\n",
        "        attention_mask=inputs[\"attention_mask\"],#.to('cuda'),  # Move attention mask tensors to GPU\n",
        "        max_length=max_length,\n",
        "        num_beams=num_beams,\n",
        "        #early_stopping=True,\n",
        "        length_penalty=length_penalty,\n",
        "        temperature=1.9,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        #max_new_tokens=100,\n",
        "        top_k=50,  # Use top-k sampling\n",
        "        top_p=0.7\n",
        "\n",
        "    )\n",
        "\n",
        "    # Decode the output\n",
        "    summary = tokenizer.batch_decode(loaded_model_outputs, skip_special_tokens=True)\n",
        "    return summary[0]\n",
        "\n",
        "# Example prompt\n",
        "prompt = \"\"\"\n",
        "you are an expert in resume summary.\n",
        "Resume:\n",
        "Olivia Wilson | Human Resources Coordinator Experience: Employee relations, benefits administration, and talent acquisition (4 years)Skilled in HRIS, conflict resolution, and legal compliance Education: Bachelor's degree in Human Resources Management, JKL University\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "# Generate and print the summary\n",
        "summary = summarize(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Summary:\", summary)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a9a293eecc2845f782b19d3538502565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0e5f09b779c409eb20074aded83884d",
              "IPY_MODEL_2717d6293d884469964560df007fdc81",
              "IPY_MODEL_2795a32ef8bd49c6876c0a4c06dd754e"
            ],
            "layout": "IPY_MODEL_b65c8ebc05084eb4b9fe85ffb782fba4"
          }
        },
        "b0e5f09b779c409eb20074aded83884d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1ad1506220d4207a82bf609e09bd266",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fd509685d2294e26af4fac7f50111674",
            "value": "Map:â€‡100%"
          }
        },
        "2717d6293d884469964560df007fdc81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b57d6c38e7c742f8a2b6d5bce6e83d7c",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52fcd9bf3e6b48d58581f39d2d193038",
            "value": 80
          }
        },
        "2795a32ef8bd49c6876c0a4c06dd754e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77e749d36771437fa6489e95e101b745",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b9622e4d9370480d8de53a91467553bd",
            "value": "â€‡80/80â€‡[00:00&lt;00:00,â€‡195.68â€‡examples/s]"
          }
        },
        "b65c8ebc05084eb4b9fe85ffb782fba4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1ad1506220d4207a82bf609e09bd266": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd509685d2294e26af4fac7f50111674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b57d6c38e7c742f8a2b6d5bce6e83d7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52fcd9bf3e6b48d58581f39d2d193038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77e749d36771437fa6489e95e101b745": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9622e4d9370480d8de53a91467553bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b64414a657f34a4ba693e7e32b4bc931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b7597bd8c1f44dc871ee670ad3b8e7b",
              "IPY_MODEL_c9c7eb338e494a50bd30680ff17e148e",
              "IPY_MODEL_07a1c3e858f14cb5baf9dabf0c36d852"
            ],
            "layout": "IPY_MODEL_52bb2f8df57941c68595b5b957160c83"
          }
        },
        "0b7597bd8c1f44dc871ee670ad3b8e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cc39e168071459d9e9cfca150c859e7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_02418721a61940dc9ee8c4bbbfe0fb52",
            "value": "Map:â€‡100%"
          }
        },
        "c9c7eb338e494a50bd30680ff17e148e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0091994f8624c3f85e61d028c5ae317",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b69750180ee6460e88db70931fa450b4",
            "value": 20
          }
        },
        "07a1c3e858f14cb5baf9dabf0c36d852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9fc614f8c024bc1aeb2593b5563a519",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a8403fde68184f72aa8650d1e3e96a8d",
            "value": "â€‡20/20â€‡[00:00&lt;00:00,â€‡â€‡7.36â€‡examples/s]"
          }
        },
        "52bb2f8df57941c68595b5b957160c83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cc39e168071459d9e9cfca150c859e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02418721a61940dc9ee8c4bbbfe0fb52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0091994f8624c3f85e61d028c5ae317": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b69750180ee6460e88db70931fa450b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9fc614f8c024bc1aeb2593b5563a519": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8403fde68184f72aa8650d1e3e96a8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cd9043b0e7a441dbc6315e0ba279dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f4ae6e80a6846b88e8a325c2b86a767",
              "IPY_MODEL_2522929143ea453182c1a1b6e255d28d",
              "IPY_MODEL_63a13b044370423aa5400bc66ce2f83f"
            ],
            "layout": "IPY_MODEL_9791d0d4fde84483b244f5f9b12125f3"
          }
        },
        "0f4ae6e80a6846b88e8a325c2b86a767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ded80243d9f64e659a65bfe7505c6506",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_030128bd0e144e73b9cd721d636a5544",
            "value": "Map:â€‡100%"
          }
        },
        "2522929143ea453182c1a1b6e255d28d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f1d5008ee124d66b2e8a22b3e160d16",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9f8b0728821484180d98f8d5ea7f3df",
            "value": 80
          }
        },
        "63a13b044370423aa5400bc66ce2f83f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0e81846a1074dd088c7af5722a788b7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f46d870e3ba6476183d7a66a569fa93c",
            "value": "â€‡80/80â€‡[00:00&lt;00:00,â€‡628.22â€‡examples/s]"
          }
        },
        "9791d0d4fde84483b244f5f9b12125f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ded80243d9f64e659a65bfe7505c6506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "030128bd0e144e73b9cd721d636a5544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f1d5008ee124d66b2e8a22b3e160d16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9f8b0728821484180d98f8d5ea7f3df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0e81846a1074dd088c7af5722a788b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f46d870e3ba6476183d7a66a569fa93c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfad7e7afa9d4a7893f55bbdf7886ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98da5a0cca1b496095bf164dcb157bc6",
              "IPY_MODEL_9d9245e0f13848049fdfac94f35167d9",
              "IPY_MODEL_794b35debcb34fdfbb99263241b2b444"
            ],
            "layout": "IPY_MODEL_060b8683a53e409a9782bb9db9876ed4"
          }
        },
        "98da5a0cca1b496095bf164dcb157bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aa27e15c83145358d08e579099b1f3c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c4298f931e354e98820bfa1b24552bff",
            "value": "Map:â€‡100%"
          }
        },
        "9d9245e0f13848049fdfac94f35167d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3012d22ff8142d4aa3d2f886a5074a9",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_375a39e3824b4a6880ed8afcba7ab85d",
            "value": 20
          }
        },
        "794b35debcb34fdfbb99263241b2b444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc6e3dbdd0184512a5efded3146f8f1c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_eacd4084c6284a2998ee61dbcdb97377",
            "value": "â€‡20/20â€‡[00:00&lt;00:00,â€‡228.87â€‡examples/s]"
          }
        },
        "060b8683a53e409a9782bb9db9876ed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aa27e15c83145358d08e579099b1f3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4298f931e354e98820bfa1b24552bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3012d22ff8142d4aa3d2f886a5074a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "375a39e3824b4a6880ed8afcba7ab85d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc6e3dbdd0184512a5efded3146f8f1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eacd4084c6284a2998ee61dbcdb97377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}